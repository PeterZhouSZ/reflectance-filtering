name: "Networks_in_barrista"
force_backward: false
state {
  phase: TRAIN
  level: 0
  stage: "fit"
}
debug_info: false
layer {
  name: "input"
  type: "Input"
  top: "images"
  input_param {
    shape: { dim: 1 dim: 3 dim: 256 dim: 256 }
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "images"
  top: "conv0"
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    dilation: 1
  }
}
layer {
  name: "relu0"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
  relu_param {
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1"
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    dilation: 1
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    dilation: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    dilation: 1
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    dilation: 1
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
  }
}
layer {
  name: "concat_skip_layers"
  type: "Concat"
  bottom: "conv0"
  bottom: "conv1"
  bottom: "conv2"
  bottom: "conv3"
  bottom: "conv4"
  top: "concat_skip_layers"
  concat_param {
  }
}
layer {
  name: "fuse_skip_layers"
  type: "Convolution"
  bottom: "concat_skip_layers"
  top: "RS_est_before_sigmoid"
  convolution_param {
    num_output: 1
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "sigmoid_after_fusing"
  type: "Sigmoid"
  bottom: "RS_est_before_sigmoid"
  top: "reflectance_intensity"
  sigmoid_param {
  }
}
